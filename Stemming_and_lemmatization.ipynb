{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTG4H+MAvfJpYGfWQNseWZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DeepeshMadane/NLP_Machine_learning/blob/main/Stemming_and_lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Porter steammer"
      ],
      "metadata": {
        "id": "vIu3Dx9end9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UlR-q_cFjcxK"
      },
      "outputs": [],
      "source": [
        "words = ['eating','moving','moved','goes','gone','running','runs','eaten','fixing','fixed','history']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()\n",
        "for word in words:\n",
        "    print(word+\"---> \" +stemming.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ08O6ugj2Df",
        "outputId": "b1828c8d-0903-4a0a-b7b6-d1df5cc5ce38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---> eat\n",
            "moving---> move\n",
            "moved---> move\n",
            "goes---> goe\n",
            "gone---> gone\n",
            "running---> run\n",
            "runs---> run\n",
            "eaten---> eaten\n",
            "fixing---> fix\n",
            "fixed---> fix\n",
            "history---> histori\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RegexpStemmer"
      ],
      "metadata": {
        "id": "xZOtb2x0njPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing$|s$|able$|ness$|y$|d$',min=4)\n",
        "for word in words:\n",
        "    print(word+\"---> \"+regexp.stem(word))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEkdkOL6kHGj",
        "outputId": "d0ec5e0a-208c-491f-8fb3-8e20ac388fc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---> eat\n",
            "moving---> mov\n",
            "moved---> move\n",
            "goes---> goe\n",
            "gone---> gone\n",
            "running---> runn\n",
            "runs---> run\n",
            "eaten---> eaten\n",
            "fixing---> fix\n",
            "fixed---> fixe\n",
            "history---> histor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SnowBall Stemmer"
      ],
      "metadata": {
        "id": "XqvmWJ3PndUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snow = SnowballStemmer('english')\n",
        "for word in words:\n",
        "    print(word+\"---> \"+snow.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBtBq2ibxBJu",
        "outputId": "370cba73-1a76-4e45-d8f2-e0931f93e87d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---> eat\n",
            "moving---> move\n",
            "moved---> move\n",
            "goes---> goe\n",
            "gone---> gone\n",
            "running---> run\n",
            "runs---> run\n",
            "eaten---> eaten\n",
            "fixing---> fix\n",
            "fixed---> fix\n",
            "history---> histori\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snow.stem('sportingly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DIWFuge4xRKg",
        "outputId": "db76c48d-aca9-45a0-dcfd-be17f8060449"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sport'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemming.stem('sportingly')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tM-E4BLMyYDQ",
        "outputId": "deccce3b-c34b-422a-da11-9d886edd57b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sportingli'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lemmatization"
      ],
      "metadata": {
        "id": "KFrEa7cFEwsr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## WordNetLemmatizer"
      ],
      "metadata": {
        "id": "ae1Iia4bE0Qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZekB_eFjFTBp",
        "outputId": "0b02f30a-2a55-40be-f507-c0486ddd55c3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "n - noun\n",
        "v - verb\n",
        "a - adjective\n",
        "r - adverb\n",
        "for parameter post in lemmatize\n",
        "\"\"\"\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "for word in words:\n",
        "    print(word+\"---> \"+lemmatizer.lemmatize(word,pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNk93HXjybvl",
        "outputId": "e23a62bf-663f-4562-bfc2-036f4ce8d136"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating---> eat\n",
            "moving---> move\n",
            "moved---> move\n",
            "goes---> go\n",
            "gone---> go\n",
            "running---> run\n",
            "runs---> run\n",
            "eaten---> eat\n",
            "fixing---> fix\n",
            "fixed---> fix\n",
            "history---> history\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u5CBpooiFPxG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}